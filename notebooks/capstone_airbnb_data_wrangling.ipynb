{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "This notebook will contain all of the code used to clean the data within a Pandas dataframe and engineer new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopy.distance\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/listings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74840, 74)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of all columns within the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'listing_url',\n",
       " 'scrape_id',\n",
       " 'last_scraped',\n",
       " 'name',\n",
       " 'description',\n",
       " 'neighborhood_overview',\n",
       " 'picture_url',\n",
       " 'host_id',\n",
       " 'host_url',\n",
       " 'host_name',\n",
       " 'host_since',\n",
       " 'host_location',\n",
       " 'host_about',\n",
       " 'host_response_time',\n",
       " 'host_response_rate',\n",
       " 'host_acceptance_rate',\n",
       " 'host_is_superhost',\n",
       " 'host_thumbnail_url',\n",
       " 'host_picture_url',\n",
       " 'host_neighbourhood',\n",
       " 'host_listings_count',\n",
       " 'host_total_listings_count',\n",
       " 'host_verifications',\n",
       " 'host_has_profile_pic',\n",
       " 'host_identity_verified',\n",
       " 'neighbourhood',\n",
       " 'neighbourhood_cleansed',\n",
       " 'neighbourhood_group_cleansed',\n",
       " 'latitude',\n",
       " 'longitude',\n",
       " 'property_type',\n",
       " 'room_type',\n",
       " 'accommodates',\n",
       " 'bathrooms',\n",
       " 'bathrooms_text',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'amenities',\n",
       " 'price',\n",
       " 'minimum_nights',\n",
       " 'maximum_nights',\n",
       " 'minimum_minimum_nights',\n",
       " 'maximum_minimum_nights',\n",
       " 'minimum_maximum_nights',\n",
       " 'maximum_maximum_nights',\n",
       " 'minimum_nights_avg_ntm',\n",
       " 'maximum_nights_avg_ntm',\n",
       " 'calendar_updated',\n",
       " 'has_availability',\n",
       " 'availability_30',\n",
       " 'availability_60',\n",
       " 'availability_90',\n",
       " 'availability_365',\n",
       " 'calendar_last_scraped',\n",
       " 'number_of_reviews',\n",
       " 'number_of_reviews_ltm',\n",
       " 'number_of_reviews_l30d',\n",
       " 'first_review',\n",
       " 'last_review',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_value',\n",
       " 'license',\n",
       " 'instant_bookable',\n",
       " 'calculated_host_listings_count',\n",
       " 'calculated_host_listings_count_entire_homes',\n",
       " 'calculated_host_listings_count_private_rooms',\n",
       " 'calculated_host_listings_count_shared_rooms',\n",
       " 'reviews_per_month']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns that are based on review data\n",
    "\n",
    "review_cols_drop = ['number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d',\n",
    "                    'first_review', 'last_review', 'review_scores_rating',\n",
    "                    'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin',\n",
    "                    'review_scores_communication', 'review_scores_location',\n",
    "                    'review_scores_value', 'reviews_per_month']\n",
    "\n",
    "df.drop(review_cols_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns related to the host that I won't be using as features\n",
    "\n",
    "host_cols_drop = ['host_url', 'host_name', 'host_location',\n",
    "                  'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood',\n",
    "                  'host_listings_count', 'host_total_listings_count', 'calculated_host_listings_count_entire_homes',\n",
    "                  'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms',]\n",
    "\n",
    "df.drop(host_cols_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns that can't or wouldn't be useful as predictor variables\n",
    "\n",
    "useless_cols_drop = ['scrape_id', 'last_scraped', 'picture_url', 'neighbourhood',\n",
    "                     'neighbourhood_group_cleansed', 'bathrooms', 'minimum_nights',\n",
    "                     'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights',\n",
    "                     'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
    "                     'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability',\n",
    "                     'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "                     'calendar_last_scraped', 'license']\n",
    "\n",
    "df.drop(useless_cols_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the variables with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <td>29439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_since</th>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_about</th>\n",
       "      <td>34283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time</th>\n",
       "      <td>41905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>41905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <td>39343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_identity_verified</th>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms_text</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>4677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "name                       23\n",
       "description              3126\n",
       "neighborhood_overview   29439\n",
       "host_since               1981\n",
       "host_about              34283\n",
       "host_response_time      41905\n",
       "host_response_rate      41905\n",
       "host_acceptance_rate    39343\n",
       "host_is_superhost        1981\n",
       "host_has_profile_pic     1981\n",
       "host_identity_verified   1981\n",
       "bathrooms_text            173\n",
       "bedrooms                 4677\n",
       "beds                     1192"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values = pd.DataFrame(df.isnull().sum())\n",
    "null_values = null_values[null_values[0] != 0]\n",
    "null_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following text variables all have blank values in their columns. I'm going to fill them in with the word 'null' to avoid having to remove these properties from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the null values in the following columns rather than removing any rows\n",
    "\n",
    "df.name.fillna('null',inplace=True)\n",
    "df.description.fillna('null',inplace=True)\n",
    "df.neighborhood_overview.fillna('null',inplace=True)\n",
    "df.host_about.fillna('null',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've created a function to allow me to look at the distribution of values in each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for analysing a variable\n",
    "\n",
    "def variable_viewer(x):\n",
    "    values = df[x].value_counts(sort=False)\n",
    "    proportion = df[x].value_counts(sort=False,normalize='all')\n",
    "    variable_df = pd.DataFrame({'value_counts': values, 'proportion': proportion})\n",
    "    return variable_df.sort_values('value_counts', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new distance features using the long and lat variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance from \"centre\" of London"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making an assertion that trafalgar square is the centre of London."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafalgar_square = (51.504831314, -0.123499506)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance_from_center'] = df.apply(lambda row: geopy.distance.distance((row['latitude'],row['longitude']),trafalgar_square).km,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest train station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv('../data/Stations_20180921.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to calculate the closest train station to each property and how far away it is in km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def station_checker(lat,long):\n",
    "#     station = ''\n",
    "#     station_distance = 1000\n",
    "#     for station_,lat_, long_ in zip(stations.NAME,stations.y,stations.x):\n",
    "#         calculated_distance = geopy.distance.distance((lat,long),(lat_,long_)).km\n",
    "#         if calculated_distance < station_distance:\n",
    "#             station_distance = calculated_distance\n",
    "#             station = station_\n",
    "#     return station, station_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the results in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station_dict = {'index': [], 'nearest_station': [], 'station_distance': []}\n",
    "\n",
    "\n",
    "# for i in df.index:\n",
    "#     station_checker_result = station_checker(df.loc[i]['latitude'],df.loc[i]['longitude'])\n",
    "#     station_dict['index'].append(i)\n",
    "#     station_dict['nearest_station'].append(station_checker_result[0])\n",
    "#     station_dict['station_distance'].append(station_checker_result[1])\n",
    "\n",
    "# station_df = pd.DataFrame(station_dict)\n",
    "# station_df.to_csv('../data/station_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe out of the station data\n",
    "\n",
    "station_df = pd.read_csv('../data/station_df.csv',index_col=1)\n",
    "\n",
    "station_df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the series to our dataframe\n",
    "\n",
    "df['nearest_station'] = station_df.nearest_station\n",
    "df['station_distance'] = station_df.station_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding average rental price for the area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data sourced from https://www.ons.gov.uk/peoplepopulationandcommunity/housing/adhocs/12871privaterentalmarketinlondonjanuarytodecember2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = geopy.geocoders.Nominatim(user_agent='myGeocoder',timeout=10)\n",
    "\n",
    "rgeocode = RateLimiter(locator.reverse, min_delay_seconds=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to find out the postcode of the property using the co-ordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def postcode_generator(row):\n",
    "#     co_ordinates = (row['y'],row['x'])\n",
    "#     try:\n",
    "#         location = rgeocode(co_ordinates)\n",
    "#         postcode = location.raw['address']['postcode'].split()[0]\n",
    "#         return postcode\n",
    "#     except:\n",
    "#         return \"error\"\n",
    "\n",
    "# stations['postcode'] = stations.apply(postcode_generator,axis=1)\n",
    "\n",
    "# stations.to_csv('../data/stations_with_postcode.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv('../data/stations_with_postcode.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the stations dataframe for the join\n",
    "\n",
    "stations.rename(columns={'NAME': 'nearest_station'},inplace=True)\n",
    "\n",
    "stations.set_index('nearest_station',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the stations data with our dataframe\n",
    "\n",
    "df = df.join(stations, on='nearest_station', how='left')\n",
    "\n",
    "# removing the columns we don't need\n",
    "\n",
    "df.drop(['FID','OBJECTID','EASTING','NORTHING','x','y', 'LINES'],axis=1,inplace=True)\n",
    "\n",
    "df.rename({'NETWORK':'rail_network','Zone':'tfl_zone'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the rental prices dataframe for the join\n",
    "\n",
    "rental_prices = pd.read_csv('../data/londonrentalstatisticsq42020.csv')\n",
    "rental_prices['Mean'] = rental_prices.Mean.apply(lambda x: float(x.replace(',','')))\n",
    "\n",
    "rental_prices.set_index('Postcode District',inplace=True)\n",
    "rental_prices.drop('Bedroom Category',axis=1,inplace=True)\n",
    "rental_prices.rename(columns={'Mean': 'mean_monthly_rent'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(rental_prices,on='postcode',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the null values in the mean rent column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rent_filler(row):\n",
    "    if np.isnan(row['mean_monthly_rent']):\n",
    "        mean_neighbourhood_rent = df[df.neighbourhood_cleansed==row['neighbourhood_cleansed']]['mean_monthly_rent'].mean()\n",
    "        return mean_neighbourhood_rent\n",
    "    else:\n",
    "        return row['mean_monthly_rent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['mean_monthly_rent'] = df.apply(rent_filler,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing dollar sign from the price variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing dollar sign from price column and transforming values in to floats\n",
    "\n",
    "df['price'] = df.price.apply(lambda x: float(x.replace('$','').replace('.00','').replace(',','')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the properties with zero value for price from the dataframe. From looking at the Airbnb listings, these seem to be properties with zero availability. This is likely why Inside Airbnb were unable to scrape the data for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Removing the properties with a zero value for price\n",
    "\n",
    "# price_0 = df[df.price==0]\n",
    "\n",
    "# price_0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(price_0.index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engineering the host response time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'listing_url', 'name', 'description', 'neighborhood_overview',\n",
       "       'host_id', 'host_since', 'host_about', 'host_response_time',\n",
       "       'host_response_rate', 'host_acceptance_rate', 'host_is_superhost',\n",
       "       'host_verifications', 'host_has_profile_pic', 'host_identity_verified',\n",
       "       'neighbourhood_cleansed', 'latitude', 'longitude', 'property_type',\n",
       "       'room_type', 'accommodates', 'bathrooms_text', 'bedrooms', 'beds',\n",
       "       'amenities', 'price', 'instant_bookable',\n",
       "       'calculated_host_listings_count', 'distance_from_center',\n",
       "       'nearest_station', 'station_distance', 'rail_network', 'tfl_zone',\n",
       "       'postcode', 'mean_monthly_rent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                   0.559928\n",
       "within an hour        0.224506\n",
       "within a few hours    0.093560\n",
       "within a day          0.076951\n",
       "a few days or more    0.045056\n",
       "Name: host_response_time, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.host_response_time.value_counts(normalize='all',dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.host_response_time.fillna('unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown               0.559928\n",
       "within an hour        0.224506\n",
       "within a few hours    0.093560\n",
       "within a day          0.076951\n",
       "a few days or more    0.045056\n",
       "Name: host_response_time, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.host_response_time.value_counts(normalize='all',dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['host_acceptance_rate'] = df.host_acceptance_rate.str.replace('%','').fillna(np.nan).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def host_filler(x):\n",
    "    if not np.isnan(x) and x >= 75:\n",
    "        return \"Above or equal to 75%\"\n",
    "    else:\n",
    "        return \"Below 75%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['host_acceptance_rate'] = df.host_acceptance_rate.apply(host_filler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['host_response_rate'] = df.host_response_rate.str.replace('%','').fillna(np.nan).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['host_response_rate'] = df.host_response_rate.apply(host_filler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the host_since, first_review and last_review columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the host since column to datetime\n",
    "\n",
    "df['host_since'] = pd.to_datetime(df.host_since)\n",
    "\n",
    "data_pulled_date = pd.to_datetime('2021-06-04')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes more sense to view how long a host has been active on Airbnb for then which date they joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new column to show how many days the host has been active for\n",
    "\n",
    "def day_transformer(x):\n",
    "    delta = data_pulled_date - x\n",
    "    return delta.days\n",
    "\n",
    "df['host_since'] = df.host_since.apply(day_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DON'T NEED THE CELL BELOW?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # I'll also use the previous function to transform the first_review and last_review columns\n",
    "\n",
    "# df['first_review'] = pd.to_datetime(df['first_review'])\n",
    "# df['last_review'] = pd.to_datetime(df['last_review'])\n",
    "\n",
    "# df['first_review'] = df.first_review.apply(day_transformer)\n",
    "# df['last_review'] = df.last_review.apply(day_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and filling the bathrooms_text variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the bathrooms_text variable from text to a continuous variable\n",
    "\n",
    "# function to check if string value is numeric\n",
    "\n",
    "def is_number(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# function to convert bathrooms_text values\n",
    "\n",
    "def bathroom_cleaner(x):\n",
    "    try:\n",
    "        split = x.lower().split()\n",
    "        if is_number(split[0]):\n",
    "            return float(split[0])\n",
    "        elif 'half-bath' in split:\n",
    "            return float(0.5)\n",
    "        else:\n",
    "            return float(x)\n",
    "    except:\n",
    "        return x\n",
    "    \n",
    "# replacing old bathrooms_text variable\n",
    "\n",
    "df['bathrooms_text'] = df.bathrooms_text.apply(bathroom_cleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the bathrooms_text variable with the mean value depending on the room_type and bedrooms value of the property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bathrooms_notnull = df[(df.bathrooms_text.notna()) & (df.bedrooms.notna())][['bedrooms','room_type','bathrooms_text']]\n",
    "\n",
    "def bathroom_filler(row):\n",
    "    if np.isnan(row['bathrooms_text']):\n",
    "        try:\n",
    "            mean_value = round(bathrooms_notnull[(bathrooms_notnull.room_type==row['room_type']) & (bathrooms_notnull.bedrooms==row['bedrooms'])]['bathrooms_text'].mean())\n",
    "            return float(mean_value)\n",
    "        except:\n",
    "            return row['bathrooms_text'] \n",
    "    else:\n",
    "        return row['bathrooms_text']\n",
    "\n",
    "df['bathrooms_text'] = df.apply(bathroom_filler,axis=1)\n",
    "\n",
    "bathrooms_null = df[df.bathrooms_text.isna()]\n",
    "\n",
    "df.drop(bathrooms_null.index,axis=0,inplace=True)\n",
    "df['bathrooms_text'] = df.bathrooms_text.apply(lambda x: float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'bathrooms_text': 'bathrooms', 'neighbourhood_cleansed': 'neighbourhood'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling null values in beds and bedrooms columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding out the mean number of bedrooms for each room type\n",
    "\n",
    "bedrooms_notnull = df[(df.bedrooms.notnull())][['room_type','bedrooms','bathrooms']].copy()\n",
    "\n",
    "# code to replace null bedroom values with mean values based on room type and number of bathrooms\n",
    "\n",
    "\n",
    "def bedroom_cleaner(row):\n",
    "    if np.isnan(row['bedrooms']):\n",
    "        try:\n",
    "            mean_value = round(bedrooms_notnull[(bedrooms_notnull.room_type==row['room_type']) & (bedrooms_notnull.bathrooms==row['bathrooms'])]['bedrooms'].mean())\n",
    "            return mean_value\n",
    "        except:\n",
    "            return round(row['bathrooms'])\n",
    "    else:\n",
    "        return row['bedrooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bedrooms'] = df.apply(bedroom_cleaner,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the null and zero values in beds\n",
    "\n",
    "df['beds'] = df.apply(lambda row: row['bedrooms'] if np.isnan(row['beds']) or row['beds']==0 else row['beds'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the property_type column\n",
    "\n",
    "At the moment the property type column contains too many variables, some with very few values. I'm hoping that a model will perform better if these values are combined in to umbrella categories instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.property_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new property type categories\n",
    "\n",
    "property_categories = ['apartment', 'house', 'townhouse', 'condominium',\n",
    "                       'hotel', 'boutique hotel', 'bed and breakfast', 'loft',\n",
    "                       'guest suite', 'guesthouse', 'private room', 'aparthotel',\n",
    "                      'bungalow', 'hostel', 'boat', 'cottage', 'bungalow', 'villa', 'houseboat', 'other']\n",
    "\n",
    "# function to sort the property column in to new categories\n",
    "\n",
    "def property_cleaner(x):\n",
    "    split = x.lower().split()\n",
    "    if (' ').join(split[-3:]) in property_categories:\n",
    "        return (' ').join(split[-3:])\n",
    "    elif (' ').join(split[-2:]) in property_categories:\n",
    "        return (' ').join(split[-2:])\n",
    "    elif split[-1]=='houseboat':\n",
    "        return 'boat'\n",
    "    elif split[-1] in property_categories:\n",
    "        return split[-1]\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "# apply function to property_type column\n",
    "\n",
    "df['property_type'] = df.property_type.apply(property_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new columns to show whether the properties have text variables such as description, host_about etc.\n",
    "\n",
    "df['description_provided'] = df.description.apply(lambda x: 0 if x == 'null' else 1)\n",
    "df['neighborhood_overview_provided'] = df.neighborhood_overview.apply(lambda x: 0 if x == 'null' else 1)\n",
    "df['host_about_provided'] = df.host_about.apply(lambda x: 0 if x == 'null' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling null values in reviews per month with 0\n",
    "\n",
    "df['reviews_per_month'].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = pd.DataFrame(df.isnull().sum())\n",
    "null_values = null_values[null_values[0] != 0]\n",
    "null_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new variables to show length of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_columns = ['name', 'description', 'neighborhood_overview', 'host_about']\n",
    "\n",
    "def text_counter(text):\n",
    "    if text != 'null':\n",
    "        split = text.split()\n",
    "        return len(split)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for column in nlp_columns:\n",
    "    df[column+'_length'] = df[column].apply(text_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting true/false columns to binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_binarise = ['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified',\n",
    "                      'has_availability', 'instant_bookable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarise(x):\n",
    "    if x=='t':\n",
    "        return 1\n",
    "    elif x=='f':\n",
    "        return 0\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_binarise:\n",
    "    df[column] = df[column].apply(binarise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing properties with no reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of the properties with insane outlier values have no reviews. Although this will remove a lot of observations from my data set, it will also provide me with more accurate data to build a model around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[(df.room_type=='Private room')&(df.price>750)].number_of_reviews.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[(df.room_type=='Entire home/apt')&(df.price>2000)].number_of_reviews.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all properties that have never been reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df.number_of_reviews==0].index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling in properties that have no host values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_sum = df.isnull().sum()\n",
    "\n",
    "null_sum[(null_sum!=0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to fill the null values in the \"host\" columns with 0, under the assumption that they are new hosts and do not have the features represented by the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the host_since column with mean values\n",
    "\n",
    "df.host_since.fillna(value=df.host_since.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_columns = ['host_is_superhost','host_listings_count','host_has_profile_pic','host_identity_verified']\n",
    "\n",
    "for column in host_columns:\n",
    "    df[column].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummifying the host_verification and amenities columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_values = []\n",
    "\n",
    "for hv_list in df.host_verifications:\n",
    "    if eval(hv_list) != None:\n",
    "        lst = eval(hv_list)\n",
    "        for value in lst:\n",
    "            if value not in hv_values:\n",
    "                hv_values.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the list values in the host_verification column in to binary dummified columns\n",
    "\n",
    "# compiling all of the unique values within the lists\n",
    "\n",
    "hv_values = []\n",
    "\n",
    "for hv_list in df.host_verifications:\n",
    "    if eval(hv_list) != None:\n",
    "        lst = eval(hv_list)\n",
    "        for value in lst:\n",
    "            if value not in hv_values:\n",
    "                hv_values.append(value)\n",
    "            \n",
    "# creating a dictionary to store the binary values for each value    \n",
    "\n",
    "hv_dict = {}\n",
    "\n",
    "for value in hv_values:\n",
    "    hv_dict[value] = []\n",
    "\n",
    "# adding the binary values to the dictionary    \n",
    "    \n",
    "for hv_list in df.host_verifications:\n",
    "    if eval(hv_list) != None:\n",
    "        lst = eval(hv_list)\n",
    "        for key in hv_dict.keys():\n",
    "            if key in lst:\n",
    "                hv_dict[key].append(1)\n",
    "            else:\n",
    "                hv_dict[key].append(0)\n",
    "    else:\n",
    "        for key in hv_dict.keys():\n",
    "            hv_dict[key].append(0)\n",
    "            \n",
    "# checking that my dictionary has recorded a value for each observation\n",
    "\n",
    "for key in hv_dict.keys():\n",
    "    if len(hv_dict[key]) != df.shape[0]:\n",
    "        print(key, len(hv_dict[key]), \"error has occurred\")\n",
    "        \n",
    "# discarding the values that are present in a very small number of observations         \n",
    "        \n",
    "hv_columns = []\n",
    "\n",
    "for key in hv_dict.keys():\n",
    "    if sum(hv_dict[key]) >= df.shape[0]*0.01:\n",
    "        hv_columns.append(key)\n",
    "        \n",
    "# adding the columns to the dataframe\n",
    "\n",
    "for column in hv_columns:\n",
    "    df[\"host_verifications_\"+column] = hv_dict[column]\n",
    "    \n",
    "# dropping the host_verification column from my dataframe\n",
    "\n",
    "df.drop('host_verifications',axis=1, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the list values in the amenities column in to binary dummified columns\n",
    "\n",
    "amenities_values = []\n",
    "\n",
    "for amenities_list in df.amenities:\n",
    "    if eval(amenities_list) != None:\n",
    "        lst = eval(amenities_list)\n",
    "        for value in lst:\n",
    "            if value not in amenities_values:\n",
    "                amenities_values.append(value)\n",
    "            \n",
    "amenities_dict = {}\n",
    "\n",
    "for value in amenities_values:\n",
    "    amenities_dict[value] = []    \n",
    "    \n",
    "for amenities_list in df.amenities:\n",
    "    if eval(amenities_list) != None:\n",
    "        lst = eval(amenities_list)\n",
    "        for key in amenities_dict.keys():\n",
    "            if key in lst:\n",
    "                amenities_dict[key].append(1)\n",
    "            else:\n",
    "                amenities_dict[key].append(0)\n",
    "    else:\n",
    "        for key in amenities_dict.keys():\n",
    "            amenities_dict[key].append(0)\n",
    "            \n",
    "amenities_columns = []\n",
    "\n",
    "for key in amenities_dict.keys():\n",
    "    if sum(amenities_dict[key]) >= df.shape[0]*0.01:\n",
    "        amenities_columns.append(key)            \n",
    "        \n",
    "for column in amenities_columns:\n",
    "    df[\"amenities_\"+column] = amenities_dict[column]        \n",
    "    \n",
    "df.drop('amenities',axis=1, inplace=True)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing outliers\n",
    "\n",
    "#### Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lots of outliers in the target variable......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to make the assumption that a lot of these outliers are one of the following:\n",
    "\n",
    "- erroneously scraped (some of the properties have zero availability, which might have affected whichever software was used to scrape the data)\n",
    "- the price of the property has been raised by the host to prevent people from renting it (as an alternative to removing the listing?)\n",
    "- the property has been listed as a joke - see toilet room :)\n",
    "- the price has been set incorrectly by mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping outliers based on the conditions below\n",
    "\n",
    "room_outliers = df[(df.room_type=='Private room')&(df.price>1000)]\n",
    "house_outliers = df[(df.room_type=='Entire home/apt')&(df.price>10000)]\n",
    "\n",
    "df.drop(room_outliers.index, axis=0, inplace=True)\n",
    "df.drop(house_outliers.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "sns.boxplot(x=df.price,y=df.room_type,ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating the outliers in the Hotel room and Shared room categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.room_type=='Hotel room')&(df.price>500)].T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These properties seem legitimate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.room_type=='Shared room')&(df.price>400)].T.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This property does not seem to be accurately priced. I'm going to remove it from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_rooms_drop = [37661065, 17420384, 21425945]\n",
    "\n",
    "df.drop(df[df.id.isin(shared_rooms_drop)].index,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating the big price outliers in the Entire home/apt variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.room_type=='Entire home/apt')&(df.price>4000)].sort_values('price',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entire_houses_drop = [36657089, 11851238, 23706138, 39383869, 7974622, 40518546]\n",
    "\n",
    "\n",
    "df.drop(df[df.id.isin(entire_houses_drop)].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "sns.boxplot(x=df.price,y=df.room_type,ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the outliers in the bathrooms and bedrooms categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This property gives a price per night for an individual property, yet lists all of the bathrooms and bedrooms for the range of properties the host offers on one one page: https://www.airbnb.com/rooms/43483035 65471\n",
    "https://www.airbnb.com/rooms/47089782 71819\n",
    "\n",
    "\n",
    "This property has erroneous listingsL: https://www.airbnb.com/rooms/40222389\t58992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_outliers = df[(df.listing_url=='https://www.airbnb.com/rooms/43483035')|(df.listing_url=='https://www.airbnb.com/rooms/47089782')|(df.listing_url=='https://www.airbnb.com/rooms/40222389')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing these properties from the dataset\n",
    "\n",
    "df.drop(df_drop_outliers.index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-checking for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = pd.DataFrame(df.isnull().sum())\n",
    "null_values = null_values[null_values[0] != 0]\n",
    "null_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured Plan\n",
    "\n",
    "Perform modelling on features without reviews first? Then model including reviews.\n",
    "\n",
    "Capture metadata aspects about the reviews? HOw many reviews and over which timeframe?\n",
    "\n",
    "- Create data dictionary - DONE\n",
    "- Data Cleaning - DONE\n",
    "- EDA - partial\n",
    "- Feature Engineering + Further Data Cleaning - partial\n",
    "- Linear Regression or Classification? - DONE\n",
    "- Fit Model on Listings Dataset to Predict Prices - DONE\n",
    "- Fit Model on Reviews Dataset to Predict Prices - DONE\n",
    "- Combine Both to Predict Prices - DONE\n",
    "- Visualise findings - use the Tableau location function\n",
    "- Perform Clustering on the Reviews - what insights can we gather? Create word clouds\n",
    "- Predict reviews based on NLP of reviews\n",
    "- What are people looking for when they stay at an Airbnb?\n",
    "- Which neighborhoods are the most popular? Which are the most expensive?\n",
    "- Can we see any trends on where people like to stay?\n",
    "- Are there other features that we can use from different datasets\n",
    "\n",
    "When transforming data - do train and test split before transforming. This means that your model isn't already aware words that appear in your test set. You need to turn-off drop first, though, and set the parameter to ignore any unknown words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- can we apply the model to other cities?\n",
    "\n",
    "To-Do List\n",
    "\n",
    "Data Cleaning:\n",
    "\n",
    "- use median values rather than mean values (mean values will be swayed more by outliers)\n",
    "- simplify the categorisation of the property type variable\n",
    "- apply lower and higher limits to the price variable to deal with outliers\n",
    "- simplify the amenities + host binarised variables\n",
    "- create a new column to show the average property price for each host_id\n",
    "- bring in geographical proximity of attractions as target variables\n",
    "\n",
    "Variable Transformation:\n",
    "\n",
    "- look at distributions of continuous/discrete variables - do they need transforming?\n",
    "- look in to log transforming the continuous variables (naive-Bayes lessons)\n",
    "\n",
    "Modelling:\n",
    "\n",
    "- review the use of NLP - could we instead look at key words within the variables? This might be a better option for the title of the \n",
    "- can we use neural networks?\n",
    "\n",
    "good visualisations: https://towardsdatascience.com/predicting-airbnb-prices-with-deep-learning-part-2-how-to-improve-your-nightly-price-50ea8bc2bd29"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
