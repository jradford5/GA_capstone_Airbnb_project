{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "This notebook will contain all of the code used to clean the Airbnb listings data within a pandas dataframe and engineer new features for the purpose of building a regression to predict the prices of Airbnb properties in London."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries/modules that will be used within this notebook\n",
    "\n",
    "import pandas as pd\n",
    "import geopy.distance\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the listings.csv document as a pandas dataframe\n",
    "\n",
    "df = pd.read_csv(\"../data/listings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74840, 74)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe has 74 columns and 74840 rows\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Directly below is an alphabetical list of the 74 columns that exist within the Airbnb listings dataset. In the following code, I'm going to decide which columns will be useful for this project, discard the columns that are irrelevant or duplicates and \"clean\" the columns that, in their current format (e.g. the price column has a dollar sign at the beginning of each value and is thus stored as a piece of text rather than a number), can't be used for modelling purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accommodates',\n",
       " 'amenities',\n",
       " 'availability_30',\n",
       " 'availability_365',\n",
       " 'availability_60',\n",
       " 'availability_90',\n",
       " 'bathrooms',\n",
       " 'bathrooms_text',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'calculated_host_listings_count',\n",
       " 'calculated_host_listings_count_entire_homes',\n",
       " 'calculated_host_listings_count_private_rooms',\n",
       " 'calculated_host_listings_count_shared_rooms',\n",
       " 'calendar_last_scraped',\n",
       " 'calendar_updated',\n",
       " 'description',\n",
       " 'first_review',\n",
       " 'has_availability',\n",
       " 'host_about',\n",
       " 'host_acceptance_rate',\n",
       " 'host_has_profile_pic',\n",
       " 'host_id',\n",
       " 'host_identity_verified',\n",
       " 'host_is_superhost',\n",
       " 'host_listings_count',\n",
       " 'host_location',\n",
       " 'host_name',\n",
       " 'host_neighbourhood',\n",
       " 'host_picture_url',\n",
       " 'host_response_rate',\n",
       " 'host_response_time',\n",
       " 'host_since',\n",
       " 'host_thumbnail_url',\n",
       " 'host_total_listings_count',\n",
       " 'host_url',\n",
       " 'host_verifications',\n",
       " 'id',\n",
       " 'instant_bookable',\n",
       " 'last_review',\n",
       " 'last_scraped',\n",
       " 'latitude',\n",
       " 'license',\n",
       " 'listing_url',\n",
       " 'longitude',\n",
       " 'maximum_maximum_nights',\n",
       " 'maximum_minimum_nights',\n",
       " 'maximum_nights',\n",
       " 'maximum_nights_avg_ntm',\n",
       " 'minimum_maximum_nights',\n",
       " 'minimum_minimum_nights',\n",
       " 'minimum_nights',\n",
       " 'minimum_nights_avg_ntm',\n",
       " 'name',\n",
       " 'neighborhood_overview',\n",
       " 'neighbourhood',\n",
       " 'neighbourhood_cleansed',\n",
       " 'neighbourhood_group_cleansed',\n",
       " 'number_of_reviews',\n",
       " 'number_of_reviews_l30d',\n",
       " 'number_of_reviews_ltm',\n",
       " 'picture_url',\n",
       " 'price',\n",
       " 'property_type',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_value',\n",
       " 'reviews_per_month',\n",
       " 'room_type',\n",
       " 'scrape_id']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discarding columns\n",
    "\n",
    "The first thing I'm going to do is discard the columns that I can immediately see won't be useful for modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to build a model to predict the prices of Airbnb properties that could be used by hosts when they list a new property. Since new properties aren't going to have any existing review data, I'm not going to be able use any review columns within the dataset to help predict their prices. All of the columns below are going to be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_cols_drop = ['number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d',\n",
    "                    'first_review', 'last_review', 'review_scores_rating',\n",
    "                    'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin',\n",
    "                    'review_scores_communication', 'review_scores_location',\n",
    "                    'review_scores_value', 'reviews_per_month']\n",
    "\n",
    "df.drop(review_cols_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the columns related to the property host that I'm going to be dropping. Some of them are objectively useless as predictor variables (e.g. host_url, host_picture_url) and others are columns that I believe aren't useful (e.g. the name of the host or where they are based)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_cols_drop = ['host_since', 'host_url', 'host_verifications', 'host_name', 'host_location',\n",
    "                  'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood',\n",
    "                  'host_listings_count', 'host_total_listings_count', 'calculated_host_listings_count_entire_homes',\n",
    "                  'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms',]\n",
    "\n",
    "df.drop(host_cols_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a mish-mash of columns that either contain no values, are duplicates of other columns or, in my opinion, won't be useful predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_cols_drop = ['scrape_id', 'last_scraped', 'picture_url', 'neighbourhood',\n",
    "                     'neighbourhood_group_cleansed', 'bathrooms', 'minimum_nights',\n",
    "                     'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights',\n",
    "                     'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
    "                     'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability',\n",
    "                     'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "                     'calendar_last_scraped', 'license']\n",
    "\n",
    "df.drop(useless_cols_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I start any data cleaning, I'm going to rename a couple of the columns so that their titles make more sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'bathrooms_text': 'bathrooms', 'neighbourhood_cleansed': 'neighbourhood'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling null values\n",
    "\n",
    "Let's have a look at the remaining columns that have null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <td>29439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_about</th>\n",
       "      <td>34283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time</th>\n",
       "      <td>41905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>41905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <td>39343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_identity_verified</th>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>4677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "name                       23\n",
       "description              3126\n",
       "neighborhood_overview   29439\n",
       "host_about              34283\n",
       "host_response_time      41905\n",
       "host_response_rate      41905\n",
       "host_acceptance_rate    39343\n",
       "host_is_superhost        1981\n",
       "host_has_profile_pic     1981\n",
       "host_identity_verified   1981\n",
       "bedrooms                 4677\n",
       "beds                     1192"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values = pd.DataFrame(df.isnull().sum())\n",
    "null_values = null_values[null_values[0] != 0]\n",
    "null_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the text columns containing null values, I'm going to fill them in with the word 'null' to avoid having to remove these rows from my dataset. Later on this project, I'll be able to process this dataset so that these words are ignored by my model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the null values in the following columns rather than removing any rows\n",
    "\n",
    "df.name.fillna('null',inplace=True)\n",
    "df.description.fillna('null',inplace=True)\n",
    "df.neighborhood_overview.fillna('null',inplace=True)\n",
    "df.host_about.fillna('null',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beds and bedrooms columns\n",
    "\n",
    "To begin with, I'm going to deal with the bedrooms column as it contains more null values than the beds column. \n",
    "\n",
    "The assumption I'm making is that in the majority of the properties, the number of beds will match the number of bedrooms. As such, where the beds value is not null or 0, I'm going to use it to fill in the corresponding null bedrooms value. Where the beds value is null or zero, I'm going to fill it in with the median bedrooms value, which is 1, instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in the null values in the bedrooms with the beds value, as these will generally be a straight match\n",
    "\n",
    "def bedroom_cleaner(row):\n",
    "    if np.isnan(row['bedrooms']) and row['beds'] != 0 and not np.isnan(row['beds']):\n",
    "        return row['beds']\n",
    "    else:\n",
    "        return df.bedrooms.median()\n",
    "    \n",
    "df['bedrooms'] = df.apply(bedroom_cleaner,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the beds column, I'm just going to fill the null values with the column's median value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling null values in the beds column with the median values\n",
    "\n",
    "df.beds.fillna(df.beds.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've created a function to allow me to look at the distribution of values in each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function for analysing a variable\n",
    "\n",
    "# def variable_viewer(x):\n",
    "#     values = df[x].value_counts(sort=False)\n",
    "#     proportion = df[x].value_counts(sort=False,normalize='all')\n",
    "#     variable_df = pd.DataFrame({'value_counts': values, 'proportion': proportion})\n",
    "#     return variable_df.sort_values('value_counts', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting true/false columns to binary values\n",
    "\n",
    "For the columns containing 't' (true), 'f' (false) and null values. I'm going to convert them to contain binary values, where 1 represents true and 0 is false or null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_binarise = ['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_binarise:\n",
    "    df[column] = df[column].apply(lambda x: 1 if x=='t' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host response time\n",
    "\n",
    "A larger number of the host response time values are null values. So we can one-hot encode this column for modelling, I'm going to convert the null values to 'unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                   0.559928\n",
       "within an hour        0.224506\n",
       "within a few hours    0.093560\n",
       "within a day          0.076951\n",
       "a few days or more    0.045056\n",
       "Name: host_response_time, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.host_response_time.value_counts(normalize='all',dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.host_response_time.fillna('unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host acceptance rate\n",
    "\n",
    "Like previously, a lot of the values in the host acceptance rate column are null. This causes an issue as there are too many null values to fill with an aggregated value, but if we don't fill them, then we aren't able to use the non-null acceptance rates as they are.\n",
    "\n",
    "The best solution in this instance is to categorize the values before one-hot encoding them. The Airbnb host guide (https://blog.atairbnb.com/hospitality-starts-with-accepting-reservations/) states that the top hosts have an acceptance rate of 75% or above, so I'll categorize the rates in my dataset depending on whether they're in this bracket or if they either aren't or are null. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN     0.525695\n",
       "100%    0.166635\n",
       "0%      0.042718\n",
       "96%     0.020604\n",
       "50%     0.018520\n",
       "98%     0.015794\n",
       "95%     0.015032\n",
       "94%     0.011130\n",
       "67%     0.011077\n",
       "99%     0.010115\n",
       "Name: host_acceptance_rate, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.host_acceptance_rate.value_counts(normalize='all', dropna=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['host_acceptance_rate'] = df.host_acceptance_rate.str.replace('%','').fillna(np.nan).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to categorize host acceptance rates\n",
    "\n",
    "def host_filler(x):\n",
    "    if not np.isnan(x) and x >= 75:\n",
    "        return \"Above or equal to 75%\"\n",
    "    else:\n",
    "        return \"Below 75% or not displayed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['host_acceptance_rate'] = df.host_acceptance_rate.apply(host_filler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host response rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the host response rate column has a similar issue as the host acceptance rate, it makes sense to solve it using the same method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN     0.559928\n",
       "100%    0.258739\n",
       "0%      0.029329\n",
       "90%     0.014645\n",
       "97%     0.013709\n",
       "98%     0.011317\n",
       "50%     0.011184\n",
       "95%     0.009514\n",
       "80%     0.009460\n",
       "67%     0.008685\n",
       "Name: host_response_rate, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.host_response_rate.value_counts(normalize='all', dropna=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the % sign, filling null values with np.nan and converting the values to floats\n",
    "\n",
    "df['host_response_rate'] = df.host_response_rate.str.replace('%','').fillna(np.nan).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['host_response_rate'] = df.host_response_rate.apply(host_filler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-checking for null values\n",
    "\n",
    "No more columns with null values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values = pd.DataFrame(df.isnull().sum())\n",
    "null_values = null_values[null_values[0] != 0]\n",
    "null_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with columns on an individual basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bathrooms column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the example below shows, the column showing the number of bathrooms in each property is stored as a text value. The code I've written beneath the example will convert the bathroom value from text to a float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT EXAMPLE WHAT THE BATHROOMS TEXT COLUMN LOOKS LIKE\n",
    "\n",
    "df.bathrooms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check if string value is numeric\n",
    "\n",
    "def is_number(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# function to convert bathrooms_text values\n",
    "\n",
    "def bathroom_cleaner(x):\n",
    "    try:\n",
    "        split = x.lower().split()\n",
    "        if is_number(split[0]):\n",
    "            return float(split[0])\n",
    "        elif 'half-bath' in split:\n",
    "            return float(0.5)\n",
    "        else:\n",
    "            return float(x)\n",
    "    except:\n",
    "        return x\n",
    "    \n",
    "# replacing old bathrooms_text variable\n",
    "\n",
    "df['bathrooms_text'] = df.bathrooms_text.apply(bathroom_cleaner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the property_type column\n",
    "\n",
    "At the moment the property type column contains too many variables, some with very few values. I'm hoping that a model will perform better if these values are combined in to umbrella categories instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.property_type.value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new property type categories\n",
    "\n",
    "property_categories = ['apartment', 'house', 'townhouse', 'condominium',\n",
    "                       'hotel', 'boutique hotel', 'bed and breakfast', 'loft',\n",
    "                       'guest suite', 'guesthouse', 'private room', 'aparthotel',\n",
    "                      'bungalow', 'hostel', 'boat', 'cottage', 'bungalow', 'villa', 'houseboat', 'other']\n",
    "\n",
    "# function to sort the property column in to new categories\n",
    "\n",
    "def property_simplifier(x):\n",
    "    split = x.lower().split()\n",
    "    if (' ').join(split[-3:]) in property_categories:\n",
    "        return (' ').join(split[-3:])\n",
    "    elif (' ').join(split[-2:]) in property_categories:\n",
    "        return (' ').join(split[-2:])\n",
    "    elif split[-1]=='houseboat':\n",
    "        return 'boat'\n",
    "    elif split[-1] in property_categories:\n",
    "        return split[-1]\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "# apply function to property_type column\n",
    "\n",
    "df['property_type_simplified'] = df.property_type.apply(property_simplifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apartment_cats = ['apartment', 'condominium', 'loft', 'guest suite', 'private room',\n",
    "                  'hotel', 'boutique hotel', 'bed and breakfast', 'guest suite',\n",
    "                  'aparthotel', 'hostel']\n",
    "\n",
    "df['property_type_basic'] = df.property_type_simplified.apply(lambda x: \"apartment\" if x in apartment_cats else \"house\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.property_type_basic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummifying amenities column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discarding the host_verification values - not important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the list values in the amenities column in to binary dummified columns\n",
    "\n",
    "amenities_values = []\n",
    "\n",
    "for amenities_list in df.amenities:\n",
    "    if eval(amenities_list) != None:\n",
    "        lst = eval(amenities_list)\n",
    "        for value in lst:\n",
    "            if value not in amenities_values:\n",
    "                amenities_values.append(value)\n",
    "            \n",
    "amenities_dict = {}\n",
    "\n",
    "for value in amenities_values:\n",
    "    amenities_dict[value] = []    \n",
    "    \n",
    "for amenities_list in df.amenities:\n",
    "    if eval(amenities_list) != None:\n",
    "        lst = eval(amenities_list)\n",
    "        for key in amenities_dict.keys():\n",
    "            if key in lst:\n",
    "                amenities_dict[key].append(1)\n",
    "            else:\n",
    "                amenities_dict[key].append(0)\n",
    "    else:\n",
    "        for key in amenities_dict.keys():\n",
    "            amenities_dict[key].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amenities_count_dict = {}\n",
    "\n",
    "for key in amenities_dict.keys():\n",
    "    amenities_count_dict[key] = sum(amenities_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "over_500 = {}\n",
    "\n",
    "for item in amenities_count_dict.keys():\n",
    "    if amenities_count_dict[item] >= 500:\n",
    "        over_500[item] = amenities_count_dict[item]\n",
    "\n",
    "sorted(over_500.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_cats_dict = {'air_conditioning': 'air conditioning', \n",
    "                       'bbq': 'bbq',\n",
    "                       'baby_facilities': 'baby|crib|changing table|high chair', \n",
    "                       'balcony_or_patio': 'patio|balcony',\n",
    "                       'bath': 'bathtub|bath', \n",
    "                       'bed_linen': 'bed linens', \n",
    "                       'cable_tv': 'cable',\n",
    "                       'child_friendly': 'children', \n",
    "                       'coffee_maker': 'coffee|nespresso', \n",
    "                       'cooking_facilities': 'oven|stove',\n",
    "                       'dishwasher': 'dishwasher', \n",
    "                       'fridge_freezer': 'refrigerator|fridge|freezer',\n",
    "                       'garden': 'backyard|garden', \n",
    "                       'has_workspace': 'workspace', \n",
    "                       'host_greets_you': 'host greets you',\n",
    "                       'long_term_stays': 'long term stays allowed',\n",
    "                       'luggage_dropoff': 'luggage dropoff', \n",
    "                       'lock_on_bedroom_door': 'lock on bedroom',\n",
    "                       'luxury_facilities': 'gym|hot tub|pool|sauna', \n",
    "                       'private_entrance': 'private entrance',\n",
    "                       'toiletries': 'soap|conditioner|shampoo|shower gel', \n",
    "                       'tumble_dryer': 'Dryer',\n",
    "                       'tv': 'tv'}\n",
    "\n",
    "for category in amenities_cats_dict.keys():\n",
    "    if category == 'tumble_dryer':\n",
    "        df.loc[df['amenities'].str.contains(amenities_cats_dict[category], case = True), category] = 1\n",
    "        df.loc[~df['amenities'].str.contains(amenities_cats_dict[category], case = True), category] = 0\n",
    "    else:    \n",
    "        df.loc[df['amenities'].str.contains(amenities_cats_dict[category], case = False), category] = 1\n",
    "        df.loc[~df['amenities'].str.contains(amenities_cats_dict[category], case = False), category] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing dollar sign from the price variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.price.str.replace('$','').str.replace('.00','').str.replace(',','').replace('',0).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the properties with zero value for price from the dataframe. From looking at the Airbnb listings, these seem to be properties with zero availability. This is likely why Inside Airbnb were unable to scrape the data for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Removing the properties with a zero value for price\n",
    "\n",
    "# price_0 = df[df.price==0]\n",
    "\n",
    "# price_0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(price_0.index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE IS WHERE TO ADDRESS AND RESOLVE THE ISSUES WITH THE PRICE VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new distance features using the long and lat variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance from \"centre\" of London"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making an assertion that trafalgar square is the centre of London."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafalgar_square = (51.504831314, -0.123499506)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance_from_center'] = df.apply(lambda row: geopy.distance.distance((row['latitude'],row['longitude']),trafalgar_square).km,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest train station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv('../data/Stations_20180921.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to calculate the closest train station to each property and how far away it is in km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def station_checker(lat,long):\n",
    "#     station = ''\n",
    "#     station_distance = 1000\n",
    "#     for station_,lat_, long_ in zip(stations.NAME,stations.y,stations.x):\n",
    "#         calculated_distance = geopy.distance.distance((lat,long),(lat_,long_)).km\n",
    "#         if calculated_distance < station_distance:\n",
    "#             station_distance = calculated_distance\n",
    "#             station = station_\n",
    "#     return station, station_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the results in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station_dict = {'index': [], 'nearest_station': [], 'station_distance': []}\n",
    "\n",
    "\n",
    "# for i in df.index:\n",
    "#     station_checker_result = station_checker(df.loc[i]['latitude'],df.loc[i]['longitude'])\n",
    "#     station_dict['index'].append(i)\n",
    "#     station_dict['nearest_station'].append(station_checker_result[0])\n",
    "#     station_dict['station_distance'].append(station_checker_result[1])\n",
    "\n",
    "# station_df = pd.DataFrame(station_dict)\n",
    "# station_df.to_csv('../data/station_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe out of the station data\n",
    "\n",
    "station_df = pd.read_csv('../data/station_df.csv',index_col=1)\n",
    "\n",
    "station_df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the series to our dataframe\n",
    "\n",
    "df['nearest_station'] = station_df.nearest_station\n",
    "df['station_distance'] = station_df.station_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding average rental price for the area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data sourced from https://www.ons.gov.uk/peoplepopulationandcommunity/housing/adhocs/12871privaterentalmarketinlondonjanuarytodecember2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = geopy.geocoders.Nominatim(user_agent='myGeocoder',timeout=10)\n",
    "\n",
    "rgeocode = RateLimiter(locator.reverse, min_delay_seconds=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to find out the postcode of the property using the co-ordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def postcode_generator(row):\n",
    "#     co_ordinates = (row['y'],row['x'])\n",
    "#     try:\n",
    "#         location = rgeocode(co_ordinates)\n",
    "#         postcode = location.raw['address']['postcode'].split()[0]\n",
    "#         return postcode\n",
    "#     except:\n",
    "#         return \"error\"\n",
    "\n",
    "# stations['postcode'] = stations.apply(postcode_generator,axis=1)\n",
    "\n",
    "# stations.to_csv('../data/stations_with_postcode.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv('../data/stations_with_postcode.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the stations dataframe for the join\n",
    "\n",
    "stations.rename(columns={'NAME': 'nearest_station'},inplace=True)\n",
    "\n",
    "stations.set_index('nearest_station',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the stations data with our dataframe\n",
    "\n",
    "df = df.join(stations, on='nearest_station', how='left')\n",
    "\n",
    "# removing the columns we don't need\n",
    "\n",
    "df.drop(['FID','OBJECTID','EASTING','NORTHING','x','y', 'LINES'],axis=1,inplace=True)\n",
    "\n",
    "df.rename({'NETWORK':'rail_network','Zone':'tfl_zone'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the rental prices dataframe for the join\n",
    "\n",
    "rental_prices = pd.read_csv('../data/londonrentalstatisticsq42020.csv')\n",
    "rental_prices['Mean'] = rental_prices.Mean.apply(lambda x: float(x.replace(',','')))\n",
    "\n",
    "rental_prices.set_index('Postcode District',inplace=True)\n",
    "rental_prices.drop('Bedroom Category',axis=1,inplace=True)\n",
    "rental_prices.rename(columns={'Mean': 'mean_monthly_rent'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(rental_prices,on='postcode',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the null values in the mean rent column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rent_filler(row):\n",
    "    if np.isnan(row['mean_monthly_rent']):\n",
    "        mean_neighbourhood_rent = df[df.neighbourhood_cleansed==row['neighbourhood_cleansed']]['mean_monthly_rent'].mean()\n",
    "        return mean_neighbourhood_rent\n",
    "    else:\n",
    "        return row['mean_monthly_rent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['mean_monthly_rent'] = df.apply(rent_filler,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding serviced variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serviced_function(x):\n",
    "    serviced_prop_types_list = ['serviced', 'hotel', 'bed and breakfast', 'aparthotel', 'hostel']\n",
    "    if any([prop_type in x for prop_type in serviced_prop_types_list]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['serviced_property'] = df.property_type.apply(serviced_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new columns to show whether the properties have text variables such as description, host_about etc.\n",
    "\n",
    "df['description_provided'] = df.description.apply(lambda x: 0 if x == 'null' else 1)\n",
    "df['neighborhood_overview_provided'] = df.neighborhood_overview.apply(lambda x: 0 if x == 'null' else 1)\n",
    "df['host_about_provided'] = df.host_about.apply(lambda x: 0 if x == 'null' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = pd.DataFrame(df.isnull().sum())\n",
    "null_values = null_values[null_values[0] != 0]\n",
    "null_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new variables to show length of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_columns = ['name', 'description', 'neighborhood_overview', 'host_about']\n",
    "\n",
    "def text_counter(text):\n",
    "    if text != 'null':\n",
    "        split = text.split()\n",
    "        return len(split)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for column in nlp_columns:\n",
    "    df[column+'_length'] = df[column].apply(text_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-Do List\n",
    "\n",
    "Data Cleaning:\n",
    "\n",
    "- apply lower and higher limits to the price variable to deal with outliers - include visualisation showing the issue with outliers\n",
    "- tidy notebook: remove cells that aren't needed, add code comments, write-up markdown cells\n",
    "\n",
    "Variable Transformation:\n",
    "\n",
    "- look at distributions of continuous/discrete variables - do they need transforming?\n",
    "- look in to log transforming the continuous variables (naive-Bayes lessons)\n",
    "\n",
    "Modelling:\n",
    "\n",
    "- review the use of NLP - could we instead look at key words within the variables? This might be a better option for the title variable\n",
    "- can we use neural networks?\n",
    "\n",
    "good visualisations: https://towardsdatascience.com/predicting-airbnb-prices-with-deep-learning-part-2-how-to-improve-your-nightly-price-50ea8bc2bd29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Tracker:\n",
    "\n",
    "- added serviced column\n",
    "- removed host_since column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
