{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "This notebook will contain all of the code used to clean the Airbnb listings data within a pandas dataframe and engineer new features for the purpose of building a regression to predict the prices of Airbnb properties in London."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries/modules that will be used within this notebook\n",
    "\n",
    "import pandas as pd\n",
    "import geopy.distance\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening the listings.csv document as a pandas dataframe\n",
    "\n",
    "df = pd.read_csv(\"../data/listings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74840, 74)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe has 74 columns and 74840 rows\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Directly below is an alphabetical list of the 74 columns that exist within the Airbnb listings dataset. In the following code, I'm going to decide which columns will be useful for this project, discard the columns that are irrelevant or duplicates and \"clean\" the columns that, in their current format (e.g. the price column has a dollar sign at the beginning of each value and is thus stored as a piece of text rather than a number), can't be used for modelling purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accommodates',\n",
       " 'amenities',\n",
       " 'availability_30',\n",
       " 'availability_365',\n",
       " 'availability_60',\n",
       " 'availability_90',\n",
       " 'bathrooms',\n",
       " 'bathrooms_text',\n",
       " 'bedrooms',\n",
       " 'beds',\n",
       " 'calculated_host_listings_count',\n",
       " 'calculated_host_listings_count_entire_homes',\n",
       " 'calculated_host_listings_count_private_rooms',\n",
       " 'calculated_host_listings_count_shared_rooms',\n",
       " 'calendar_last_scraped',\n",
       " 'calendar_updated',\n",
       " 'description',\n",
       " 'first_review',\n",
       " 'has_availability',\n",
       " 'host_about',\n",
       " 'host_acceptance_rate',\n",
       " 'host_has_profile_pic',\n",
       " 'host_id',\n",
       " 'host_identity_verified',\n",
       " 'host_is_superhost',\n",
       " 'host_listings_count',\n",
       " 'host_location',\n",
       " 'host_name',\n",
       " 'host_neighbourhood',\n",
       " 'host_picture_url',\n",
       " 'host_response_rate',\n",
       " 'host_response_time',\n",
       " 'host_since',\n",
       " 'host_thumbnail_url',\n",
       " 'host_total_listings_count',\n",
       " 'host_url',\n",
       " 'host_verifications',\n",
       " 'id',\n",
       " 'instant_bookable',\n",
       " 'last_review',\n",
       " 'last_scraped',\n",
       " 'latitude',\n",
       " 'license',\n",
       " 'listing_url',\n",
       " 'longitude',\n",
       " 'maximum_maximum_nights',\n",
       " 'maximum_minimum_nights',\n",
       " 'maximum_nights',\n",
       " 'maximum_nights_avg_ntm',\n",
       " 'minimum_maximum_nights',\n",
       " 'minimum_minimum_nights',\n",
       " 'minimum_nights',\n",
       " 'minimum_nights_avg_ntm',\n",
       " 'name',\n",
       " 'neighborhood_overview',\n",
       " 'neighbourhood',\n",
       " 'neighbourhood_cleansed',\n",
       " 'neighbourhood_group_cleansed',\n",
       " 'number_of_reviews',\n",
       " 'number_of_reviews_l30d',\n",
       " 'number_of_reviews_ltm',\n",
       " 'picture_url',\n",
       " 'price',\n",
       " 'property_type',\n",
       " 'review_scores_accuracy',\n",
       " 'review_scores_checkin',\n",
       " 'review_scores_cleanliness',\n",
       " 'review_scores_communication',\n",
       " 'review_scores_location',\n",
       " 'review_scores_rating',\n",
       " 'review_scores_value',\n",
       " 'reviews_per_month',\n",
       " 'room_type',\n",
       " 'scrape_id']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discarding columns\n",
    "\n",
    "The first thing I'm going to do is discard the columns that I can immediately see won't be useful for modelling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to build a model to predict the prices of Airbnb properties that could be used by hosts when they list a new property. Since new properties aren't going to have any existing review data, I'm not going to be able use any review columns within the dataset to help predict their prices. All of the columns below are going to be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_cols_drop = ['number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d',\n",
    "                    'first_review', 'last_review', 'review_scores_rating',\n",
    "                    'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin',\n",
    "                    'review_scores_communication', 'review_scores_location',\n",
    "                    'review_scores_value', 'reviews_per_month']\n",
    "\n",
    "df.drop(review_cols_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the columns related to the property host that I'm going to be dropping. Some of them are objectively useless as predictor variables (e.g. host_url, host_picture_url) and others are columns that I believe aren't useful (e.g. the name of the host or where they are based)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_cols_drop = ['host_since', 'host_url', 'host_verifications', 'host_name', 'host_location',\n",
    "                  'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood',\n",
    "                  'host_listings_count', 'host_total_listings_count', 'calculated_host_listings_count_entire_homes',\n",
    "                  'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms',]\n",
    "\n",
    "df.drop(host_cols_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a mish-mash of columns that either contain no values, are duplicates of other columns or, in my opinion, won't be useful predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_cols_drop = ['scrape_id', 'last_scraped', 'picture_url', 'neighbourhood',\n",
    "                     'neighbourhood_group_cleansed', 'bathrooms', 'minimum_nights',\n",
    "                     'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights',\n",
    "                     'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm',\n",
    "                     'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability',\n",
    "                     'availability_30', 'availability_60', 'availability_90', 'availability_365',\n",
    "                     'calendar_last_scraped', 'license']\n",
    "\n",
    "df.drop(useless_cols_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before I start any data cleaning, I'm going to rename a couple of the columns so that their titles make more sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'bathrooms_text': 'bathrooms', 'neighbourhood_cleansed': 'neighbourhood'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling null values\n",
    "\n",
    "Let's have a look at the remaining columns that have null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <td>29439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_about</th>\n",
       "      <td>34283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_time</th>\n",
       "      <td>41905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_response_rate</th>\n",
       "      <td>41905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <td>39343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_is_superhost</th>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_has_profile_pic</th>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_identity_verified</th>\n",
       "      <td>1981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bathrooms</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bedrooms</th>\n",
       "      <td>4677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0\n",
       "name                       23\n",
       "description              3126\n",
       "neighborhood_overview   29439\n",
       "host_about              34283\n",
       "host_response_time      41905\n",
       "host_response_rate      41905\n",
       "host_acceptance_rate    39343\n",
       "host_is_superhost        1981\n",
       "host_has_profile_pic     1981\n",
       "host_identity_verified   1981\n",
       "bathrooms                 173\n",
       "bedrooms                 4677\n",
       "beds                     1192"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values = pd.DataFrame(df.isnull().sum())\n",
    "null_values = null_values[null_values[0] != 0]\n",
    "null_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the text columns containing null values, I'm going to fill them in with the word 'null' to avoid having to remove these rows from my dataset. Later on this project, I'll be able to process this dataset so that these words are ignored by my model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling the null values in the following columns rather than removing any rows\n",
    "\n",
    "df.name.fillna('null',inplace=True)\n",
    "df.description.fillna('null',inplace=True)\n",
    "df.neighborhood_overview.fillna('null',inplace=True)\n",
    "df.host_about.fillna('null',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beds and bedrooms columns\n",
    "\n",
    "To begin with, I'm going to deal with the bedrooms column as it contains more null values than the beds column. \n",
    "\n",
    "The assumption I'm making is that in the majority of the properties, the number of beds will match the number of bedrooms. As such, where the beds value is not null or 0, I'm going to use it to fill in the corresponding null bedrooms value. Where the beds value is null or zero, I'm going to fill it in with the median bedrooms value, which is 1, instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling in the null values in the bedrooms with the beds value, as these will generally be a straight match\n",
    "\n",
    "def bedroom_cleaner(row):\n",
    "    if np.isnan(row['bedrooms']) and row['beds'] != 0 and not np.isnan(row['beds']):\n",
    "        return row['beds']\n",
    "    else:\n",
    "        return df.bedrooms.median()\n",
    "    \n",
    "df['bedrooms'] = df.apply(bedroom_cleaner,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the beds column, I'm just going to fill the null values with the column's median value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling null values in the beds column with the median values\n",
    "\n",
    "df.beds.fillna(df.beds.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've created a function to allow me to look at the distribution of values in each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # function for analysing a variable\n",
    "\n",
    "# def variable_viewer(x):\n",
    "#     values = df[x].value_counts(sort=False)\n",
    "#     proportion = df[x].value_counts(sort=False,normalize='all')\n",
    "#     variable_df = pd.DataFrame({'value_counts': values, 'proportion': proportion})\n",
    "#     return variable_df.sort_values('value_counts', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting true/false columns to binary values\n",
    "\n",
    "For the columns containing 't' (true), 'f' (false) and null values. I'm going to convert them to contain binary values, where 1 represents true and 0 is false or null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_binarise = ['host_is_superhost', 'host_has_profile_pic', 'host_identity_verified', 'instant_bookable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_binarise:\n",
    "    df[column] = df[column].apply(lambda x: 1 if x=='t' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host response time\n",
    "\n",
    "A larger number of the host response time values are null values. So we can one-hot encode this column for modelling, I'm going to convert the null values to 'unknown'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN                   0.559928\n",
       "within an hour        0.224506\n",
       "within a few hours    0.093560\n",
       "within a day          0.076951\n",
       "a few days or more    0.045056\n",
       "Name: host_response_time, dtype: float64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.host_response_time.value_counts(normalize='all',dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.host_response_time.fillna('unknown',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host acceptance rate\n",
    "\n",
    "Like previously, a lot of the values in the host acceptance rate column are null. This causes an issue as there are too many null values to fill with an aggregated value, but if we don't fill them, then we aren't able to use the non-null acceptance rates as they are.\n",
    "\n",
    "The best solution in this instance is to categorize the values before one-hot encoding them. The Airbnb host guide (https://blog.atairbnb.com/hospitality-starts-with-accepting-reservations/) states that the top hosts have an acceptance rate of 75% or above, so I'll categorize the rates in my dataset depending on whether they're in this bracket or if they either aren't or are null. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN     0.525695\n",
       "100%    0.166635\n",
       "0%      0.042718\n",
       "96%     0.020604\n",
       "50%     0.018520\n",
       "98%     0.015794\n",
       "95%     0.015032\n",
       "94%     0.011130\n",
       "67%     0.011077\n",
       "99%     0.010115\n",
       "Name: host_acceptance_rate, dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.host_acceptance_rate.value_counts(normalize='all', dropna=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['host_acceptance_rate'] = df.host_acceptance_rate.str.replace('%','').fillna(np.nan).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to categorize host acceptance rates\n",
    "\n",
    "def host_filler(x):\n",
    "    if not np.isnan(x) and x >= 75:\n",
    "        return \"Above or equal to 75%\"\n",
    "    else:\n",
    "        return \"Below 75% or not displayed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['host_acceptance_rate'] = df.host_acceptance_rate.apply(host_filler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host response rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the host response rate column has a similar issue as the host acceptance rate, it makes sense to solve it using the same method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN     0.559928\n",
       "100%    0.258739\n",
       "0%      0.029329\n",
       "90%     0.014645\n",
       "97%     0.013709\n",
       "98%     0.011317\n",
       "50%     0.011184\n",
       "95%     0.009514\n",
       "80%     0.009460\n",
       "67%     0.008685\n",
       "Name: host_response_rate, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.host_response_rate.value_counts(normalize='all', dropna=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the % sign, filling null values with np.nan and converting the values to floats\n",
    "\n",
    "df['host_response_rate'] = df.host_response_rate.str.replace('%','').fillna(np.nan).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['host_response_rate'] = df.host_response_rate.apply(host_filler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bathrooms column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the example below shows, the column showing the number of bathrooms in each property is stored as a text value. The code I've written beneath the example will convert the bathroom value from text to a float.\n",
    "\n",
    "The null values are going to be filled in to match the number of bedrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1 bath', '1 shared bath', '2 baths', '1 private bath',\n",
       "       '1.5 shared baths', '1.5 baths', '0 shared baths', nan,\n",
       "       '2.5 shared baths', '2 shared baths', '2.5 baths',\n",
       "       'Shared half-bath', '4 baths', '4.5 baths', '3 baths', '0 baths',\n",
       "       '3 shared baths', '3.5 baths', 'Half-bath', '5 baths',\n",
       "       '5 shared baths', '3.5 shared baths', 'Private half-bath',\n",
       "       '7 baths', '4 shared baths', '6 baths', '6 shared baths',\n",
       "       '5.5 baths', '10 baths', '8.5 baths', '7 shared baths',\n",
       "       '6.5 baths', '8 shared baths', '17 baths', '7.5 baths', '8 baths',\n",
       "       '10.5 baths', '4.5 shared baths', '12 baths', '9 shared baths',\n",
       "       '35 baths', '10 shared baths'], dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.bathrooms.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check if string value is numeric\n",
    "\n",
    "def is_number(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "# function to convert bathrooms values in to floats and null values in to corresponding bedroom values\n",
    "\n",
    "def bathroom_cleaner(row):\n",
    "    if is_number(row['bathrooms']):\n",
    "        return row['bedrooms']\n",
    "    else:    \n",
    "        split = row['bathrooms'].lower().split()\n",
    "        if is_number(split[0]):\n",
    "            return float(split[0])\n",
    "        elif 'half-bath' in split:\n",
    "            return float(0.5)\n",
    "        else:\n",
    "            return float(row['bathrooms'])\n",
    "\n",
    "df['bathrooms'] = df.apply(bathroom_cleaner, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-checking for null values\n",
    "\n",
    "No more columns with null values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0]\n",
       "Index: []"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_values = pd.DataFrame(df.isnull().sum())\n",
    "null_values = null_values[null_values[0] != 0]\n",
    "null_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with columns on an individual basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the property type column\n",
    "\n",
    "At the moment the property type column contains too many variables, some with very few values. I don't think that this level of detail is necessary at all for my model. \n",
    "\n",
    "As the list below shows, the vast majority of properties are either an apartment or a house. Although there are quite a few edge categories (villa, boat, castle etc.), the number of these properties is tiny and won't make much of an effect when it comes to modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entire apartment                      30857\n",
       "Private room in apartment             17739\n",
       "Private room in house                 10798\n",
       "Entire house                           5331\n",
       "Private room in townhouse              1462\n",
       "Entire condominium                     1453\n",
       "Entire townhouse                        946\n",
       "Entire serviced apartment               922\n",
       "Private room in condominium             683\n",
       "Private room in bed and breakfast       599\n",
       "Room in boutique hotel                  476\n",
       "Entire loft                             423\n",
       "Room in hotel                           326\n",
       "Shared room in apartment                288\n",
       "Room in serviced apartment              254\n",
       "Private room in loft                    236\n",
       "Entire guest suite                      186\n",
       "Private room in guest suite             179\n",
       "Private room in guesthouse              172\n",
       "Shared room in house                    125\n",
       "Entire guesthouse                       123\n",
       "Room in aparthotel                      109\n",
       "Private room                            107\n",
       "Room in hostel                          100\n",
       "Private room in bungalow                 95\n",
       "Shared room in hostel                    90\n",
       "Private room in serviced apartment       82\n",
       "Room in bed and breakfast                60\n",
       "Boat                                     55\n",
       "Private room in hostel                   52\n",
       "Entire cottage                           50\n",
       "Entire bungalow                          42\n",
       "Tiny house                               36\n",
       "Private room in cottage                  35\n",
       "Entire villa                             27\n",
       "Private room in tiny house               27\n",
       "Entire place                             25\n",
       "Shared room in bed and breakfast         20\n",
       "Houseboat                                20\n",
       "Entire home/apt                          16\n",
       "Private room in earth house              15\n",
       "Entire cabin                             14\n",
       "Private room in villa                    13\n",
       "Private room in houseboat                11\n",
       "Shared room in condominium               11\n",
       "Shared room in townhouse                 11\n",
       "Private room in boat                     10\n",
       "Camper/RV                                10\n",
       "Private room in hut                       7\n",
       "Private room in casa particular           7\n",
       "Name: property_type, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.property_type.value_counts().head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, I'm going to separate properties in to a wide number of different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new property type categories\n",
    "\n",
    "property_categories = ['apartment', 'house', 'townhouse', 'condominium',\n",
    "                       'hotel', 'boutique hotel', 'bed and breakfast', 'loft',\n",
    "                       'guest suite', 'guesthouse', 'private room', 'aparthotel',\n",
    "                      'bungalow', 'hostel', 'boat', 'cottage', 'bungalow', 'villa', 'houseboat', 'other']\n",
    "\n",
    "# function to sort the property column in to new categories\n",
    "\n",
    "def property_simplifier(x):\n",
    "    split = x.lower().split()\n",
    "    if (' ').join(split[-3:]) in property_categories:\n",
    "        return (' ').join(split[-3:])\n",
    "    elif (' ').join(split[-2:]) in property_categories:\n",
    "        return (' ').join(split[-2:])\n",
    "    elif split[-1]=='houseboat':\n",
    "        return 'boat'\n",
    "    elif split[-1] in property_categories:\n",
    "        return split[-1]\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "# apply function to property_type column\n",
    "\n",
    "property_type_simplified = df.property_type.apply(property_simplifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the properies have been categorised, I'm going to split them in to 'house' and 'apartment' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "apartment_cats = ['apartment', 'condominium', 'loft', 'guest suite', 'private room',\n",
    "                  'hotel', 'boutique hotel', 'bed and breakfast', 'guest suite',\n",
    "                  'aparthotel', 'hostel']\n",
    "\n",
    "df['property_type_basic'] = property_type_simplified.apply(lambda x: \"apartment\" if x in apartment_cats else \"house\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there are a lot more apartment properties than houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apartment    55267\n",
       "house        19573\n",
       "Name: property_type_basic, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.property_type_basic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidying the amenities column\n",
    "\n",
    "The amenities column currently contains a list of every amenity that each property has. The Airbnb website allows hosts to choose from a pre-set amenity ( e.g. 'TV', 'Hair dryer', 'Kitchen' etc.) or a create a custom one. As a result of the custom option, some of the amenities are slightly untidy (there are a lot of variations on HDTV depending on the screen size!). \n",
    "\n",
    "Below is an example of a property's amenities list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"Hair dryer\", \"Essentials\", \"Washer\", \"Lockbox\", \"Iron\", \"Carbon monoxide alarm\", \"Kitchen\", \"Dedicated workspace\", \"Cooking basics\", \"Long term stays allowed\", \"Coffee maker\", \"Wifi\", \"High chair\", \"Paid parking off premises\", \"Refrigerator\", \"Stove\", \"Fire extinguisher\", \"TV\", \"Microwave\", \"Crib\", \"Pack \\\\u2019n Play/travel crib\", \"Hangers\", \"Dishes and silverware\", \"Cable TV\", \"Heating\", \"Hot water\", \"Oven\", \"Smoke alarm\"]'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.amenities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dictionary to store which amenities each property has\n",
    "\n",
    "amenities_values = []\n",
    "\n",
    "for amenities_list in df.amenities:\n",
    "    if eval(amenities_list) != None:\n",
    "        lst = eval(amenities_list)\n",
    "        for value in lst:\n",
    "            if value not in amenities_values:\n",
    "                amenities_values.append(value)\n",
    "            \n",
    "amenities_dict = {}\n",
    "\n",
    "for value in amenities_values:\n",
    "    amenities_dict[value] = []    \n",
    "    \n",
    "for amenities_list in df.amenities:\n",
    "    if eval(amenities_list) != None:\n",
    "        lst = eval(amenities_list)\n",
    "        for key in amenities_dict.keys():\n",
    "            if key in lst:\n",
    "                amenities_dict[key].append(1)\n",
    "            else:\n",
    "                amenities_dict[key].append(0)\n",
    "    else:\n",
    "        for key in amenities_dict.keys():\n",
    "            amenities_dict[key].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating another dictionary to count how many times each amenity appears in the dataset\n",
    "\n",
    "amenities_count_dict = {}\n",
    "\n",
    "for key in amenities_dict.keys():\n",
    "    amenities_count_dict[key] = sum(amenities_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Air conditioning', 5350),\n",
       " ('BBQ grill', 2480),\n",
       " ('Baby bath', 768),\n",
       " ('Baby safety gates', 554),\n",
       " ('Babysitter recommendations', 1428),\n",
       " ('Backyard', 10524),\n",
       " ('Baking sheet', 1655),\n",
       " ('Barbecue utensils', 635),\n",
       " ('Bathtub', 7583),\n",
       " ('Bed linens', 26504),\n",
       " ('Body soap', 2244),\n",
       " ('Breakfast', 9970),\n",
       " ('Building staff', 1678),\n",
       " ('Cable TV', 11057),\n",
       " ('Carbon monoxide alarm', 43235),\n",
       " ('Changing table', 641),\n",
       " ('Children’s books and toys', 2977),\n",
       " ('Children’s dinnerware', 1561),\n",
       " ('Cleaning before checkout', 2262),\n",
       " ('Cleaning products', 1286),\n",
       " ('Clothing storage', 630),\n",
       " ('Coffee maker', 16380),\n",
       " ('Conditioner', 1619),\n",
       " ('Cooking basics', 28325),\n",
       " ('Crib', 3188),\n",
       " ('Dedicated workspace', 45233),\n",
       " ('Dining table', 1225),\n",
       " ('Dishes and silverware', 30522),\n",
       " ('Dishwasher', 17673),\n",
       " ('Dryer', 32574),\n",
       " ('Drying rack for clothing', 937),\n",
       " ('Elevator', 14699),\n",
       " ('Essentials', 68333),\n",
       " ('Ethernet connection', 3002),\n",
       " ('Extra pillows and blankets', 12795),\n",
       " ('Fire extinguisher', 23633),\n",
       " ('First aid kit', 23409),\n",
       " ('Free parking on premises', 14738),\n",
       " ('Free street parking', 8017),\n",
       " ('Freezer', 2878),\n",
       " ('Game console', 837),\n",
       " ('Gym', 2585),\n",
       " ('Hair dryer', 49683),\n",
       " ('Hangers', 57902),\n",
       " ('Heating', 69480),\n",
       " ('High chair', 3545),\n",
       " ('Host greets you', 11801),\n",
       " ('Hot tub', 2937),\n",
       " ('Hot water', 42277),\n",
       " ('Hot water kettle', 1898),\n",
       " ('Indoor fireplace', 5964),\n",
       " ('Iron', 55507),\n",
       " ('Keypad', 1192),\n",
       " ('Kitchen', 67684),\n",
       " ('Laundromat nearby', 1171),\n",
       " ('Lock on bedroom door', 12776),\n",
       " ('Lockbox', 8714),\n",
       " ('Long term stays allowed', 61679),\n",
       " ('Luggage dropoff allowed', 10833),\n",
       " ('Microwave', 26304),\n",
       " ('Mini fridge', 623),\n",
       " ('Nespresso machine', 789),\n",
       " ('Oven', 27448),\n",
       " ('Pack ’n Play/travel crib', 3170),\n",
       " ('Paid parking off premises', 9445),\n",
       " ('Paid parking on premises', 2970),\n",
       " ('Patio or balcony', 10599),\n",
       " ('Pocket wifi', 853),\n",
       " ('Pool', 506),\n",
       " ('Portable fans', 1431),\n",
       " ('Private entrance', 18076),\n",
       " ('Refrigerator', 31205),\n",
       " ('Room-darkening shades', 3280),\n",
       " ('Security cameras on property', 3858),\n",
       " ('Shampoo', 47884),\n",
       " ('Shower gel', 6225),\n",
       " ('Single level home', 4392),\n",
       " ('Smart lock', 860),\n",
       " ('Smoke alarm', 63510),\n",
       " ('Stove', 24611),\n",
       " ('TV', 43712),\n",
       " ('TV with standard cable', 6805),\n",
       " ('Toaster', 1359),\n",
       " ('Washer', 62622),\n",
       " ('Waterfront', 635),\n",
       " ('Wifi', 71333),\n",
       " ('Window guards', 713),\n",
       " ('Wine glasses', 1170)]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dictionary to show which amenities appear 500 times or more\n",
    "\n",
    "over_500 = {}\n",
    "\n",
    "for item in amenities_count_dict.keys():\n",
    "    if amenities_count_dict[item] >= 500:\n",
    "        over_500[item] = amenities_count_dict[item]\n",
    "\n",
    "sorted(over_500.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having looked through the list of amenities above, I've now created a list of categories that I'm hoping have an effect on the price of a property.\n",
    "\n",
    "For each category, I'm going to a create a column in my dataset and use binary values to record whether each property has that amenity or category of amenities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_cats_dict = {'air_conditioning': 'air conditioning', \n",
    "                       'bbq': 'bbq',\n",
    "                       'baby_facilities': 'baby|crib|changing table|high chair', \n",
    "                       'balcony_or_patio': 'patio|balcony',\n",
    "                       'bath': 'bathtub|bath', \n",
    "                       'bed_linen': 'bed linens', \n",
    "                       'cable_tv': 'cable',\n",
    "                       'child_friendly': 'children', \n",
    "                       'coffee_maker': 'coffee|nespresso', \n",
    "                       'cooking_facilities': 'oven|stove',\n",
    "                       'dishwasher': 'dishwasher', \n",
    "                       'fridge_freezer': 'refrigerator|fridge|freezer',\n",
    "                       'garden': 'backyard|garden', \n",
    "                       'has_workspace': 'workspace', \n",
    "                       'host_greets_you': 'host greets you',\n",
    "                       'long_term_stays': 'long term stays allowed',\n",
    "                       'luggage_dropoff': 'luggage dropoff', \n",
    "                       'lock_on_bedroom_door': 'lock on bedroom',\n",
    "                       'luxury_facilities': 'gym|hot tub|pool|sauna', \n",
    "                       'private_entrance': 'private entrance',\n",
    "                       'toiletries': 'soap|conditioner|shampoo|shower gel', \n",
    "                       'tumble_dryer': 'Dryer',\n",
    "                       'tv': 'tv'}\n",
    "\n",
    "for category in amenities_cats_dict.keys():\n",
    "    if category == 'tumble_dryer':\n",
    "        df.loc[df['amenities'].str.contains(amenities_cats_dict[category], case = True), category] = 1\n",
    "        df.loc[~df['amenities'].str.contains(amenities_cats_dict[category], case = True), category] = 0\n",
    "    else:    \n",
    "        df.loc[df['amenities'].str.contains(amenities_cats_dict[category], case = False), category] = 1\n",
    "        df.loc[~df['amenities'].str.contains(amenities_cats_dict[category], case = False), category] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing dollar sign from the price variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.price.str.replace('$','').str.replace('.00','').str.replace(',','').replace('',0).astype('float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the properties with zero value for price from the dataframe. From looking at the Airbnb listings, these seem to be properties with zero availability. This is likely why Inside Airbnb were unable to scrape the data for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Removing the properties with a zero value for price\n",
    "\n",
    "# price_0 = df[df.price==0]\n",
    "\n",
    "# price_0.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(price_0.index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE IS WHERE TO ADDRESS AND RESOLVE THE ISSUES WITH THE PRICE VALUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new distance features using the long and lat variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance from \"centre\" of London"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making an assertion that trafalgar square is the centre of London."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trafalgar_square = (51.504831314, -0.123499506)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['distance_from_center'] = df.apply(lambda row: geopy.distance.distance((row['latitude'],row['longitude']),trafalgar_square).km,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest train station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv('../data/Stations_20180921.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to calculate the closest train station to each property and how far away it is in km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def station_checker(lat,long):\n",
    "#     station = ''\n",
    "#     station_distance = 1000\n",
    "#     for station_,lat_, long_ in zip(stations.NAME,stations.y,stations.x):\n",
    "#         calculated_distance = geopy.distance.distance((lat,long),(lat_,long_)).km\n",
    "#         if calculated_distance < station_distance:\n",
    "#             station_distance = calculated_distance\n",
    "#             station = station_\n",
    "#     return station, station_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing the results in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# station_dict = {'index': [], 'nearest_station': [], 'station_distance': []}\n",
    "\n",
    "\n",
    "# for i in df.index:\n",
    "#     station_checker_result = station_checker(df.loc[i]['latitude'],df.loc[i]['longitude'])\n",
    "#     station_dict['index'].append(i)\n",
    "#     station_dict['nearest_station'].append(station_checker_result[0])\n",
    "#     station_dict['station_distance'].append(station_checker_result[1])\n",
    "\n",
    "# station_df = pd.DataFrame(station_dict)\n",
    "# station_df.to_csv('../data/station_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dataframe out of the station data\n",
    "\n",
    "station_df = pd.read_csv('../data/station_df.csv',index_col=1)\n",
    "\n",
    "station_df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the series to our dataframe\n",
    "\n",
    "df['nearest_station'] = station_df.nearest_station\n",
    "df['station_distance'] = station_df.station_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding average rental price for the area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data sourced from https://www.ons.gov.uk/peoplepopulationandcommunity/housing/adhocs/12871privaterentalmarketinlondonjanuarytodecember2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = geopy.geocoders.Nominatim(user_agent='myGeocoder',timeout=10)\n",
    "\n",
    "rgeocode = RateLimiter(locator.reverse, min_delay_seconds=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to find out the postcode of the property using the co-ordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def postcode_generator(row):\n",
    "#     co_ordinates = (row['y'],row['x'])\n",
    "#     try:\n",
    "#         location = rgeocode(co_ordinates)\n",
    "#         postcode = location.raw['address']['postcode'].split()[0]\n",
    "#         return postcode\n",
    "#     except:\n",
    "#         return \"error\"\n",
    "\n",
    "# stations['postcode'] = stations.apply(postcode_generator,axis=1)\n",
    "\n",
    "# stations.to_csv('../data/stations_with_postcode.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv('../data/stations_with_postcode.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the stations dataframe for the join\n",
    "\n",
    "stations.rename(columns={'NAME': 'nearest_station'},inplace=True)\n",
    "\n",
    "stations.set_index('nearest_station',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joining the stations data with our dataframe\n",
    "\n",
    "df = df.join(stations, on='nearest_station', how='left')\n",
    "\n",
    "# removing the columns we don't need\n",
    "\n",
    "df.drop(['FID','OBJECTID','EASTING','NORTHING','x','y', 'LINES'],axis=1,inplace=True)\n",
    "\n",
    "df.rename({'NETWORK':'rail_network','Zone':'tfl_zone'},axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the rental prices dataframe for the join\n",
    "\n",
    "rental_prices = pd.read_csv('../data/londonrentalstatisticsq42020.csv')\n",
    "rental_prices['Mean'] = rental_prices.Mean.apply(lambda x: float(x.replace(',','')))\n",
    "\n",
    "rental_prices.set_index('Postcode District',inplace=True)\n",
    "rental_prices.drop('Bedroom Category',axis=1,inplace=True)\n",
    "rental_prices.rename(columns={'Mean': 'mean_monthly_rent'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(rental_prices,on='postcode',how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the null values in the mean rent column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rent_filler(row):\n",
    "    if np.isnan(row['mean_monthly_rent']):\n",
    "        mean_neighbourhood_rent = df[df.neighbourhood_cleansed==row['neighbourhood_cleansed']]['mean_monthly_rent'].mean()\n",
    "        return mean_neighbourhood_rent\n",
    "    else:\n",
    "        return row['mean_monthly_rent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['mean_monthly_rent'] = df.apply(rent_filler,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding serviced variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serviced_function(x):\n",
    "    serviced_prop_types_list = ['serviced', 'hotel', 'bed and breakfast', 'aparthotel', 'hostel']\n",
    "    if any([prop_type in x for prop_type in serviced_prop_types_list]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['serviced_property'] = df.property_type.apply(serviced_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new columns to show whether the properties have text variables such as description, host_about etc.\n",
    "\n",
    "df['description_provided'] = df.description.apply(lambda x: 0 if x == 'null' else 1)\n",
    "df['neighborhood_overview_provided'] = df.neighborhood_overview.apply(lambda x: 0 if x == 'null' else 1)\n",
    "df['host_about_provided'] = df.host_about.apply(lambda x: 0 if x == 'null' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_values = pd.DataFrame(df.isnull().sum())\n",
    "null_values = null_values[null_values[0] != 0]\n",
    "null_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating new variables to show length of text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_columns = ['name', 'description', 'neighborhood_overview', 'host_about']\n",
    "\n",
    "def text_counter(text):\n",
    "    if text != 'null':\n",
    "        split = text.split()\n",
    "        return len(split)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for column in nlp_columns:\n",
    "    df[column+'_length'] = df[column].apply(text_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To-Do List\n",
    "\n",
    "Data Cleaning:\n",
    "\n",
    "- apply lower and higher limits to the price variable to deal with outliers - include visualisation showing the issue with outliers\n",
    "- tidy notebook: remove cells that aren't needed, add code comments, write-up markdown cells\n",
    "\n",
    "Variable Transformation:\n",
    "\n",
    "- look at distributions of continuous/discrete variables - do they need transforming?\n",
    "- look in to log transforming the continuous variables (naive-Bayes lessons)\n",
    "\n",
    "Modelling:\n",
    "\n",
    "- review the use of NLP - could we instead look at key words within the variables? This might be a better option for the title variable\n",
    "- can we use neural networks?\n",
    "\n",
    "good visualisations: https://towardsdatascience.com/predicting-airbnb-prices-with-deep-learning-part-2-how-to-improve-your-nightly-price-50ea8bc2bd29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change Tracker:\n",
    "\n",
    "- added serviced column\n",
    "- removed host_since column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
